{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ece032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "app_train = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/application_train.csv\")\n",
    "app_test = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/application_test.csv\")\n",
    "credit_card_balance = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/credit_card_balance.csv\")\n",
    "bureau = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/bureau.csv\")\n",
    "previous = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/previous_application.csv\")\n",
    "installments = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/installments_payments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a853a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: dask[dataframe] in c:\\programdata\\anaconda3\\lib\\site-packages (2022.7.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (0.12.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2022.11.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (22.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (6.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from dask[dataframe]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[dataframe]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[dataframe]) (2022.7)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0->dask[dataframe]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaddf50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Defaulter', 346, 'Poor')\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Function to reduce memory usage\n",
    "def reduce_memory_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:  # Exclude string columns\n",
    "            if pd.api.types.is_integer_dtype(col_type):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            elif pd.api.types.is_float_dtype(col_type):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "app_train = reduce_memory_usage(app_train)\n",
    "app_test = reduce_memory_usage(app_test)\n",
    "credit_card_balance = reduce_memory_usage(credit_card_balance)\n",
    "\n",
    "#columns from credit_card_balance for merging\n",
    "columns_to_merge = ['SK_ID_CURR', 'AMT_BALANCE', 'SK_DPD']\n",
    "credit_card_balance_selected = credit_card_balance[columns_to_merge]\n",
    "\n",
    "\n",
    "app_train_dd = dd.from_pandas(app_train, npartitions=10)\n",
    "credit_card_balance_dd = dd.from_pandas(credit_card_balance_selected, npartitions=10)\n",
    "app_test_dd = dd.from_pandas(app_test[['SK_ID_CURR']], npartitions=10)\n",
    "\n",
    "#Merging DataFrames on SK_ID_CURR using Dask\n",
    "merged_data_dd = dd.merge(app_train_dd, credit_card_balance_dd, on='SK_ID_CURR', how='left')\n",
    "merged_data_dd = dd.merge(merged_data_dd, app_test_dd, on='SK_ID_CURR', how='left')\n",
    "\n",
    "merged_data = merged_data_dd.compute()\n",
    "\n",
    "#Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "merged_data['AMT_BALANCE'] = imputer.fit_transform(merged_data[['AMT_BALANCE']])\n",
    "merged_data['SK_DPD'] = SimpleImputer(strategy='median').fit_transform(merged_data[['SK_DPD']])\n",
    "\n",
    "#binary categorical features to numeric\n",
    "binary_map = {'Y': 1, 'N': 0, 'M': 0, 'F': 1}\n",
    "merged_data['FLAG_OWN_CAR'] = merged_data['FLAG_OWN_CAR'].map(binary_map)\n",
    "merged_data['CODE_GENDER'] = merged_data['CODE_GENDER'].map(binary_map)\n",
    "\n",
    "#Label encode multi-category columns\n",
    "multi_category_columns = ['NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE', 'NAME_HOUSING_TYPE', 'NAME_CONTRACT_TYPE']\n",
    "label_encoders = {}\n",
    "for col in multi_category_columns:\n",
    "    le = LabelEncoder()\n",
    "    merged_data[col] = le.fit_transform(merged_data[col])\n",
    "    label_encoders[col] = le \n",
    "\n",
    "input_parameters = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_BALANCE', 'AMT_ANNUITY', 'SK_DPD', 'CNT_CHILDREN',\n",
    "    'FLAG_OWN_CAR', 'CODE_GENDER', 'DAYS_CREDIT', 'DAYS_DECISION', 'AMT_PAYMENT', \n",
    "    'AMT_INSTALMENT', 'AMT_APPLICATION'] + multi_category_columns\n",
    "\n",
    "\n",
    "available_columns = [col for col in input_parameters if col in merged_data.columns]\n",
    "\n",
    "\n",
    "numerical_features = [col for col in available_columns if col in [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_BALANCE', 'AMT_ANNUITY', 'SK_DPD', \n",
    "    'CNT_CHILDREN', 'DAYS_CREDIT', 'DAYS_DECISION', 'AMT_PAYMENT', 'AMT_INSTALMENT', 'AMT_APPLICATION']]\n",
    "\n",
    "# Split data into features and target\n",
    "training_data = merged_data[available_columns + ['TARGET']]\n",
    "X = training_data[available_columns]\n",
    "y = training_data['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "save_dir = 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\'\n",
    "os.makedirs(save_dir, exist_ok=True) \n",
    "\n",
    "binary_map = {'Y': 1, 'N': 0, 'M': 0, 'F': 1}\n",
    "\n",
    "def calculate_credit_score(input_data):\n",
    "    # Payment history score\n",
    "    sk_dpd = input_data.get('SK_DPD', 0) \n",
    "    amt_payment = input_data.get('AMT_PAYMENT', 0)\n",
    "    amt_installment = input_data.get('AMT_INSTALMENT', 0)\n",
    "    \n",
    "    # Calculation of payment history score based on SK_DPD, AMT_PAYMENT, and AMT_INSTALMENT\n",
    "    if amt_installment > 0:\n",
    "        payment_ratio = min(amt_payment / amt_installment, 1)\n",
    "    else:\n",
    "        payment_ratio = 1 \n",
    "    payment_history_score = max(0, 1 - sk_dpd / 100) * 0.35\n",
    "    \n",
    "    # calculation of Credit utilization score based on AMT_BALANCE and AMT_CREDIT\n",
    "    amt_balance = input_data.get('AMT_BALANCE', 0)\n",
    "    amt_credit = input_data.get('AMT_CREDIT', 1) \n",
    "    credit_utilization_ratio = amt_balance / amt_credit\n",
    "    credit_utilization_score = max(0, 1 - credit_utilization_ratio) * 0.3\n",
    "    \n",
    "    #calculation of Length of credit history score based on DAYS_CREDIT and DAYS_DECISION\n",
    "    days_credit = input_data.get('DAYS_CREDIT')\n",
    "    days_decision = input_data.get('DAYS_DECISION')\n",
    "    if days_credit is not None and days_decision is not None:\n",
    "        credit_history_length = abs(days_credit - days_decision)\n",
    "        length_of_credit_history_score = min(1, credit_history_length / 3650) * 0.15  \n",
    "    else:\n",
    "        length_of_credit_history_score = 0  \n",
    "    \n",
    "    #calculation of Credit mix score based on contract type and credit type\n",
    "    name_contract_type = input_data.get('NAME_CONTRACT_TYPE', 'Unknown')\n",
    "    credit_type_score = 0.1 if name_contract_type in ['Cash loans', 'Revolving loans'] else 0\n",
    "    credit_mix_score = credit_type_score * 0.1 \n",
    "    \n",
    "    #calculation of New credit score based on AMT_APPLICATION\n",
    "    amt_application = input_data.get('AMT_APPLICATION', 0)\n",
    "    new_credit_score = min(1, amt_application / 500000) * 0.1 \n",
    "    \n",
    "    #Calculation of total credit score\n",
    "    total_credit_score = (payment_history_score + credit_utilization_score +\n",
    "                          length_of_credit_history_score + credit_mix_score + new_credit_score) * 850 \n",
    "    \n",
    "    return int(total_credit_score)\n",
    "\n",
    "def predict_default(input_data):\n",
    "    input_data = {k: v for k, v in input_data.items() if k in available_columns}\n",
    "    \n",
    "    input_data['FLAG_OWN_CAR'] = binary_map.get(input_data.get('FLAG_OWN_CAR', 'N'), 0)\n",
    "    input_data['CODE_GENDER'] = binary_map.get(input_data.get('CODE_GENDER', 'M'), 0)\n",
    "\n",
    "    for col, le in label_encoders.items():\n",
    "        if col in input_data:\n",
    "            input_data[col] = le.transform([input_data[col]])[0]\n",
    "\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    input_df[numerical_features] = scaler.transform(input_df[numerical_features])\n",
    "\n",
    "    is_defaulter = rf_model.predict(input_df)[0]\n",
    "\n",
    "    credit_score = calculate_credit_score(input_data)\n",
    "    fico_range = determine_fico_range(credit_score)\n",
    "\n",
    "    if fico_range in ['Poor', 'Fair']:\n",
    "        is_defaulter = 1 \n",
    "\n",
    "    return (\"Defaulter\" if is_defaulter else \"Non-Defaulter\"), credit_score, fico_range\n",
    "\n",
    "# FICO range \n",
    "def determine_fico_range(credit_score):\n",
    "    if credit_score >= 800:\n",
    "        return \"Exceptional\"\n",
    "    elif credit_score >= 740:\n",
    "        return \"Very Good\"\n",
    "    elif credit_score >= 670:\n",
    "        return \"Good\"\n",
    "    elif credit_score >= 580:\n",
    "        return \"Fair\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "\n",
    "# Example for prediction\n",
    "input_example = {\n",
    "    'AMT_INCOME_TOTAL': 50000,\n",
    "    'AMT_CREDIT': 200000,\n",
    "    'AMT_BALANCE': 150000,\n",
    "    'AMT_ANNUITY': 15000,\n",
    "    'SK_DPD': 5,\n",
    "    'CNT_CHILDREN': 1,\n",
    "    'FLAG_OWN_CAR': 'Y',\n",
    "    'CODE_GENDER': 'M',\n",
    "    'NAME_FAMILY_STATUS': 'Married',\n",
    "    'NAME_INCOME_TYPE': 'Working',\n",
    "    'NAME_HOUSING_TYPE': 'House / apartment',\n",
    "    'NAME_CONTRACT_TYPE': 'Cash loans',\n",
    "    'DAYS_CREDIT': -1000,\n",
    "    'DAYS_DECISION': -500,\n",
    "    'AMT_PAYMENT': 5000,\n",
    "    'AMT_INSTALMENT': 4000,\n",
    "    'AMT_APPLICATION': 250000\n",
    "}\n",
    "\n",
    "result = predict_default(input_example)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa13d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_CONTRACT_TYPE.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(rf_model, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\random_forest_model_pipeline.pkl')\n",
    "joblib.dump(scaler, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\scaler.pkl')\n",
    "\n",
    "label_encoder_NAME_FAMILY_STATUS = LabelEncoder()\n",
    "label_encoder_NAME_FAMILY_STATUS.fit(merged_data['NAME_FAMILY_STATUS'])\n",
    "\n",
    "label_encoder_NAME_INCOME_TYPE = LabelEncoder()\n",
    "label_encoder_NAME_INCOME_TYPE.fit(merged_data['NAME_INCOME_TYPE'])\n",
    "\n",
    "label_encoder_NAME_HOUSING_TYPE = LabelEncoder()\n",
    "label_encoder_NAME_HOUSING_TYPE.fit(merged_data['NAME_HOUSING_TYPE'])\n",
    "\n",
    "label_encoder_NAME_CONTRACT_TYPE = LabelEncoder()\n",
    "label_encoder_NAME_CONTRACT_TYPE.fit(merged_data['NAME_CONTRACT_TYPE'])\n",
    "\n",
    "# Save each encoder\n",
    "joblib.dump(label_encoder_NAME_FAMILY_STATUS, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_FAMILY_STATUS.pkl')\n",
    "joblib.dump(label_encoder_NAME_INCOME_TYPE, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_INCOME_TYPE.pkl')\n",
    "joblib.dump(label_encoder_NAME_HOUSING_TYPE, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_HOUSING_TYPE.pkl')\n",
    "joblib.dump(label_encoder_NAME_CONTRACT_TYPE, 'C:\\\\Users\\\\SMRUTI DESHPANDE\\\\house credit default\\\\label_encoder_NAME_CONTRACT_TYPE.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ee020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115802d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
