{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1477d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "app_train = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/application_train.csv\")\n",
    "app_test = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/application_test.csv\")\n",
    "credit_card_balance = pd.read_csv(\"C:/Users/SMRUTI DESHPANDE/house credit default/credit_card_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36dcc934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dask[dataframe] in c:\\programdata\\anaconda3\\lib\\site-packages (2022.7.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (0.12.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (22.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2.0.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (2022.11.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from dask[dataframe]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[dataframe]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->dask[dataframe]) (2022.7)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0->dask[dataframe]) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435d78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_BALANCE  AMT_ANNUITY  SK_DPD  \\\n",
      "0          0.000627    0.111235     0.270029     0.101018     0.0   \n",
      "1          0.001127    0.063613     0.270029     0.072324     0.0   \n",
      "2          0.001512    0.271554     0.270029     0.140190     0.0   \n",
      "3          0.000819    0.102247     0.270029     0.052790     0.0   \n",
      "4          0.000550    0.033708     0.270029     0.028800     0.0   \n",
      "5          0.002858    0.364998     0.270029     0.188417     0.0   \n",
      "6          0.001320    0.404242     0.270029     0.332959     0.0   \n",
      "7          0.001320    0.101124     0.270029     0.076027     0.0   \n",
      "8          0.000589    0.134831     0.270029     0.103966     0.0   \n",
      "9          0.002474    0.226831     0.236750     0.243717     0.0   \n",
      "\n",
      "   CNT_CHILDREN  FLAG_OWN_CAR  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  ...  \\\n",
      "0             0             0      0.553452      0.414298      0.693145  ...   \n",
      "1             0             1      0.106596      0.405420      0.757179  ...   \n",
      "2             1             1      0.446292      0.273412      0.605169  ...   \n",
      "3             0             0      0.833243      0.841870      0.806119  ...   \n",
      "4             1             0      0.553452      0.626365      0.575612  ...   \n",
      "5             0             1      0.553452      0.612789      0.575612  ...   \n",
      "6             0             0      0.553452      0.667446      0.777927  ...   \n",
      "7             0             1      0.553452      0.754899      0.575612  ...   \n",
      "8             1             0      0.609765      0.571462      0.575612  ...   \n",
      "9             0             1      0.553452      0.505661      0.085955  ...   \n",
      "\n",
      "   NAME_INCOME_TYPE_State servant  NAME_INCOME_TYPE_Student  \\\n",
      "0                               1                         0   \n",
      "1                               0                         0   \n",
      "2                               0                         0   \n",
      "3                               0                         0   \n",
      "4                               0                         0   \n",
      "5                               0                         0   \n",
      "6                               0                         0   \n",
      "7                               0                         0   \n",
      "8                               0                         0   \n",
      "9                               0                         0   \n",
      "\n",
      "   NAME_INCOME_TYPE_Unemployed  NAME_INCOME_TYPE_Working  \\\n",
      "0                            0                         0   \n",
      "1                            0                         1   \n",
      "2                            0                         0   \n",
      "3                            0                         1   \n",
      "4                            0                         1   \n",
      "5                            0                         1   \n",
      "6                            0                         0   \n",
      "7                            0                         0   \n",
      "8                            0                         1   \n",
      "9                            0                         0   \n",
      "\n",
      "   NAME_HOUSING_TYPE_House / apartment  NAME_HOUSING_TYPE_Municipal apartment  \\\n",
      "0                                    1                                      0   \n",
      "1                                    0                                      0   \n",
      "2                                    1                                      0   \n",
      "3                                    1                                      0   \n",
      "4                                    1                                      0   \n",
      "5                                    1                                      0   \n",
      "6                                    1                                      0   \n",
      "7                                    1                                      0   \n",
      "8                                    1                                      0   \n",
      "9                                    0                                      0   \n",
      "\n",
      "   NAME_HOUSING_TYPE_Office apartment  NAME_HOUSING_TYPE_Rented apartment  \\\n",
      "0                                   0                                   0   \n",
      "1                                   0                                   1   \n",
      "2                                   0                                   0   \n",
      "3                                   0                                   0   \n",
      "4                                   0                                   0   \n",
      "5                                   0                                   0   \n",
      "6                                   0                                   0   \n",
      "7                                   0                                   0   \n",
      "8                                   0                                   0   \n",
      "9                                   0                                   0   \n",
      "\n",
      "   NAME_HOUSING_TYPE_With parents  TARGET  \n",
      "0                               0       0  \n",
      "1                               0       0  \n",
      "2                               0       0  \n",
      "3                               0       0  \n",
      "4                               0       0  \n",
      "5                               0       0  \n",
      "6                               0       0  \n",
      "7                               0       0  \n",
      "8                               0       0  \n",
      "9                               1       1  \n",
      "\n",
      "[10 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Function to reduce memory usage\n",
    "def reduce_memory_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:  # Exclude string columns\n",
    "            if pd.api.types.is_integer_dtype(col_type):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            elif pd.api.types.is_float_dtype(col_type):\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "# Assuming your CSV files are already loaded as app_train, app_test, credit_card_balance, etc.\n",
    "\n",
    "# Step 1: Reduce memory usage for large DataFrames\n",
    "app_train = reduce_memory_usage(app_train)\n",
    "app_test = reduce_memory_usage(app_test)\n",
    "credit_card_balance = reduce_memory_usage(credit_card_balance)\n",
    "\n",
    "# Select specific columns from credit_card_balance for merging\n",
    "columns_to_merge = ['SK_ID_CURR', 'AMT_BALANCE', 'SK_DPD']\n",
    "credit_card_balance_selected = credit_card_balance[columns_to_merge]\n",
    "\n",
    "# Step 2: Use Dask for large dataset handling\n",
    "app_train_dd = dd.from_pandas(app_train, npartitions=10)\n",
    "credit_card_balance_dd = dd.from_pandas(credit_card_balance_selected, npartitions=10)\n",
    "\n",
    "# Step 3: Rename columns in app_test to avoid duplicates during the merge\n",
    "app_test_renamed = app_test[['SK_ID_CURR', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].copy()\n",
    "app_test_renamed.columns = ['SK_ID_CURR', 'TEST_EXT_SOURCE_1', 'TEST_EXT_SOURCE_2', 'TEST_EXT_SOURCE_3']\n",
    "\n",
    "# Step 4: Merge DataFrames on SK_ID_CURR using Dask\n",
    "merged_data_dd = dd.merge(app_train_dd, credit_card_balance_dd, on='SK_ID_CURR', how='left')\n",
    "merged_data_dd = dd.merge(merged_data_dd, app_test_renamed, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Step 5: Compute the final merged DataFrame\n",
    "merged_data = merged_data_dd.compute()\n",
    "\n",
    "# Step 6: Handle missing values for EXT_SOURCE columns\n",
    "ext_source_cols = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "existing_ext_source_cols = [col for col in ext_source_cols if col in merged_data.columns]\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Define imputer for EXT_SOURCE\n",
    "\n",
    "for col in existing_ext_source_cols:\n",
    "    if merged_data[col].isna().all():\n",
    "        print(f\"{col} is completely NaN and will be dropped.\")\n",
    "        merged_data.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        merged_data[col] = imputer.fit_transform(merged_data[[col]])\n",
    "\n",
    "# Step 7: Handle missing values for 'AMT_BALANCE' if it exists\n",
    "if 'AMT_BALANCE' in merged_data.columns:\n",
    "    if merged_data['AMT_BALANCE'].isna().all():\n",
    "        print(\"AMT_BALANCE is completely NaN and will be dropped.\")\n",
    "        merged_data.drop('AMT_BALANCE', axis=1, inplace=True)\n",
    "    else:\n",
    "        merged_data['AMT_BALANCE'] = imputer.fit_transform(merged_data[['AMT_BALANCE']])\n",
    "\n",
    "# Step 8: Handle missing values in SK_DPD (categorical -> numerical conversion)\n",
    "if 'SK_DPD' in merged_data.columns:\n",
    "    sk_dpd_imputer = SimpleImputer(strategy='median')\n",
    "    merged_data['SK_DPD'] = sk_dpd_imputer.fit_transform(merged_data[['SK_DPD']])\n",
    "\n",
    "# Convert the 'Y'/'N' values in 'FLAG_OWN_CAR' to 1/0\n",
    "merged_data['FLAG_OWN_CAR'] = merged_data['FLAG_OWN_CAR'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Correct: Perform one-hot encoding on 'CODE_GENDER', 'NAME_CONTRACT_TYPE', 'NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE', 'NAME_HOUSING_TYPE'\n",
    "categorical_columns = ['CODE_GENDER', 'NAME_CONTRACT_TYPE', 'NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE', 'NAME_HOUSING_TYPE']\n",
    "merged_data = pd.get_dummies(merged_data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Convert boolean columns to integers (0/1)\n",
    "boolean_columns = merged_data.select_dtypes(include='bool').columns\n",
    "merged_data[boolean_columns] = merged_data[boolean_columns].astype(int)\n",
    "\n",
    "# Step 9: Scaling numerical features\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'SK_DPD', 'AMT_BALANCE']\n",
    "numerical_columns += [col for col in existing_ext_source_cols if col in merged_data.columns]\n",
    "\n",
    "# Step 9: Scaling numerical features using MinMaxScaler instead of StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "merged_data[numerical_columns] = scaler.fit_transform(merged_data[numerical_columns])\n",
    "\n",
    "# Step 10: Select input parameters for the model\n",
    "input_parameters = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_BALANCE', 'AMT_ANNUITY', 'SK_DPD', 'CNT_CHILDREN', 'FLAG_OWN_CAR']\n",
    "\n",
    "# Add EXT_SOURCE columns if they exist\n",
    "input_parameters += [col for col in existing_ext_source_cols if col in merged_data.columns]\n",
    "\n",
    "# Add one-hot encoded columns for 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE', 'NAME_HOUSING_TYPE'\n",
    "input_parameters += [col for col in merged_data.columns if 'NAME_CONTRACT_TYPE' in col]\n",
    "input_parameters += [col for col in merged_data.columns if 'CODE_GENDER' in col]\n",
    "input_parameters += [col for col in merged_data.columns if 'NAME_FAMILY_STATUS' in col]\n",
    "input_parameters += [col for col in merged_data.columns if 'NAME_INCOME_TYPE' in col]\n",
    "input_parameters += [col for col in merged_data.columns if 'NAME_HOUSING_TYPE' in col]\n",
    "\n",
    "# Step 11: Filter merged data for input parameters and target\n",
    "training_data = merged_data[input_parameters + ['TARGET']]\n",
    "print(training_data.head(10))\n",
    "# Split the data into features and target\n",
    "X = training_data[input_parameters]\n",
    "y = training_data['TARGET']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e11cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (2.1.1)\n",
      "Requirement already satisfied: catboost in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (1.2.7)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (4.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (2.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: namex in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: rich in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\smruti deshpande\\appdata\\roaming\\python\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn xgboost catboost lightgbm matplotlib seaborn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d7ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMRUTI DESHPANDE\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Neural Network\n",
      "Accuracy: 0.9316\n",
      "F1 Score: 0.1646\n",
      "Confusion Matrix:\n",
      "[[637913   2419]\n",
      " [ 44738   4645]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for models and preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Create a function to build a DNN model for binary classification\n",
    "def create_dnn_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize a list to hold models with preprocessing steps (imputation + scaling)\n",
    "models = {\n",
    "    'Neural Network': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', MLPClassifier(max_iter=500))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(max_iter=500))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "    ]),\n",
    "    'CatBoost': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', CatBoostClassifier(silent=True))\n",
    "    ]),\n",
    "    'LightGBM': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', LGBMClassifier())\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),  # SVM performs better with scaled data\n",
    "        ('classifier', SVC(probability=True))  # Enable probability estimates for AUC-ROC\n",
    "    ]),\n",
    "    'K-Nearest Neighbors': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),  # KNN benefits from scaling\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'Naive Bayes': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', GaussianNB())  # Naive Bayes does not need scaling\n",
    "    ]),\n",
    "    'AdaBoost': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', AdaBoostClassifier())\n",
    "    ]),\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'DNN': create_dnn_model(input_dim=X_train.shape[1])  # Assuming your features are preprocessed\n",
    "}\n",
    "\n",
    "# Step 6: Model Building and Training\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'DNN':\n",
    "        # Special handling for DNN model (sequential model instead of sklearn pipeline)\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)  # Convert probabilities to binary class (0 or 1)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)  # Train the model\n",
    "        y_pred = model.predict(X_test)  # Make predictions\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # AUC-ROC Curve\n",
    "    if model_name == 'DNN':  # Special handling for DNN predict_proba\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    elif hasattr(model.named_steps['classifier'], 'predict_proba'):  # Ensure model supports predict_proba\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    else:\n",
    "        roc_auc, fpr, tpr = None, None, None\n",
    "\n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'roc_auc': roc_auc,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad9d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Step 7: Plotting AUC-ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    plt.plot(metrics['fpr'], metrics['tpr'], label=f'{model_name} (AUC = {metrics[\"roc_auc\"]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e08e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
